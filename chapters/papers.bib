@article{cnn,
  added-at = {2008-03-11T14:52:34.000+0100},
  author = {Fukushima, Kunihiko},
  biburl = {https://www.bibsonomy.org/bibtex/29ecd878c4827c46dab6b9622cfa00072/idsia},
  citeulike-article-id = {2376719},
  interhash = {303975e6400e477e91c91e7dc2c47544},
  intrahash = {9ecd878c4827c46dab6b9622cfa00072},
  journal = {Biological Cybernetics},
  keywords = {nn},
  pages = {193--202},
  priority = {2},
  timestamp = {2008-03-11T15:04:22.000+0100},
  title = {{N}eocognitron: {A} Self-Organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position},
  volume = 36,
  year = 1980
}

@article{rnn,
  added-at = {2008-09-16T23:39:07.000+0200},
  author = {Hopfield, J. J.},
  biburl = {https://www.bibsonomy.org/bibtex/24041c6a004f343806a7e47c9cd7ccf59/brian.mingus},
  description = {CCNLab BibTeX},
  interhash = {cf60d9bad127184617e0ad10ae86b78b},
  intrahash = {4041c6a004f343806a7e47c9cd7ccf59},
  journal = {Proceedings of the National Academy of Sciences},
  keywords = {nnets},
  pages = {2554-2558},
  timestamp = {2008-09-16T23:40:17.000+0200},
  title = {Neural Networks and Physical Systems with Emergent Collective Computational
	Abilities},
  volume = 79,
  year = 1982
}

@article{lstm,
  author      = {Sepp Hochreiter and JÃ¼rgen Schmidhuber},
  journal     = {Neural Computation},
  title       = {Long Short-Term Memory},
  year        = {1997},
  number      = {8},
  pages       = {1735--1780},
  volume      = {9},
  optabstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
  optdoi      = {10.1162/neco.1997.9.8.1735},
  opteprint   = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
  opturl      = {http://dx.doi.org/10.1162/neco.1997.9.8.1735},
}

@article{gru,
  author    = {Junyoung Chung and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               KyungHyun Cho and
               Yoshua Bengio},
  title     = {Empirical Evaluation of Gated Recurrent Neural Networks on Sequence
               Modeling},
  journal   = {CoRR},
  volume    = {abs/1412.3555},
  year      = {2014},
  url       = {http://arxiv.org/abs/1412.3555},
  eprinttype = {arXiv},
  eprint    = {1412.3555},
  timestamp = {Mon, 13 Aug 2018 16:47:38 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/ChungGCB14.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{transformer,
  author    = {Ashish Vaswani and
               Noam Shazeer and
               Niki Parmar and
               Jakob Uszkoreit and
               Llion Jones and
               Aidan N. Gomez and
               Lukasz Kaiser and
               Illia Polosukhin},
  title     = {Attention Is All You Need},
  journal   = {CoRR},
  volume    = {abs/1706.03762},
  year      = {2017},
  url       = {http://arxiv.org/abs/1706.03762},
  eprinttype = {arXiv},
  eprint    = {1706.03762},
  timestamp = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{vit,
  author    = {Alexey Dosovitskiy and
               Lucas Beyer and
               Alexander Kolesnikov and
               Dirk Weissenborn and
               Xiaohua Zhai and
               Thomas Unterthiner and
               Mostafa Dehghani and
               Matthias Minderer and
               Georg Heigold and
               Sylvain Gelly and
               Jakob Uszkoreit and
               Neil Houlsby},
  title     = {An Image is Worth 16x16 Words: Transformers for Image Recognition
               at Scale},
  journal   = {CoRR},
  volume    = {abs/2010.11929},
  year      = {2020},
  url       = {https://arxiv.org/abs/2010.11929},
  eprinttype = {arXiv},
  eprint    = {2010.11929},
  timestamp = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{vivit,
  author    = {Anurag Arnab and
               Mostafa Dehghani and
               Georg Heigold and
               Chen Sun and
               Mario Lucic and
               Cordelia Schmid},
  title     = {ViViT: {A} Video Vision Transformer},
  journal   = {CoRR},
  volume    = {abs/2103.15691},
  year      = {2021},
  url       = {https://arxiv.org/abs/2103.15691},
  eprinttype = {arXiv},
  eprint    = {2103.15691},
  timestamp = {Mon, 12 Apr 2021 13:42:11 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2103-15691.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}